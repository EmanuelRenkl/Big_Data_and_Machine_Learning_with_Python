{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.datasets.fetch_20newsgroups() to load data for the \n",
    "# following newsgroups: sci.crypt, sci.electronics, sci.med, and sci.\n",
    "# space (will be slow the first time!). Make sure to shuffle the data.\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news = fetch_20newsgroups(shuffle=True, categories=['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'description', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use dir() to understand the object you just used. What is the data about?\n",
    "\n",
    "dir(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "# Print the label names corresponding to the first 20 documents to verify\n",
    "# the data is not ordered.\n",
    "\n",
    "print(news['DESCR'])\n",
    "print(news['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read up on Multinomial Naive Bayes (MultiNB) classifier. How does \n",
    "# MultiNB work, what assumptions does it make? Is it well suited for \n",
    "# text analysis?\n",
    "\n",
    "# MultinomialNB implements the naive Bayes algorithm for multinomially \n",
    "# distributed data, and is one of the two classic naive Bayes variants \n",
    "# used in text classification. Thus, the multinomial Naive Bayes classifier \n",
    "# is suitable for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline consisting of a TfidfVectorizer (with english stopwords\n",
    "# provided by nltk and the stem- ming/tokenziation function provided in \n",
    "# class.\n",
    "\n",
    "import nltk\n",
    "\n",
    "_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from string import digits, punctuation\n",
    "\n",
    "remove = digits + punctuation\n",
    "_stemmer = nltk.snowball.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    \"\"\"Return tokens of document deprived of numbers and interpunctuation.\"\"\"\n",
    "    text = text.translate(str.maketrans({p: \"\" for p in remove}))\n",
    "    return [_stemmer.stem(t) for t in nltk.word_tokenize(text.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([('vecotrizer', TfidfVectorizer(stop_words=_stopwords, tokenizer=tokenize_and_stem)), ('nn', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nn__alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Perform a grid search with 2-fold cross-validation and two different \n",
    "# values for alpha. (It may make sense to use multiple cores using the \n",
    "# parameter njobs.)Whatareyourbestparameters?\n",
    "\n",
    "param_grid = {'nn__alpha': [0.00001, 0.001]}\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=2, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set using sklearn.datasets.fetch_20newsgroups(subset=\"test\").\n",
    "\n",
    "news_test = fetch_20newsgroups(categories=news[\"target_names\"], subset=\"test\")\n",
    "\n",
    "X_test = news_test['data']\n",
    "y_test = news_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to predict on the test set.\n",
    "\n",
    "preds = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      sci.crypt       0.90      0.96      0.93       396\n",
      "sci.electronics       0.94      0.88      0.91       393\n",
      "        sci.med       0.94      0.93      0.93       396\n",
      "      sci.space       0.94      0.95      0.94       394\n",
      "\n",
      "    avg / total       0.93      0.93      0.93      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the test set.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, preds,\n",
    "                               target_names=news_test[\"target_names\"])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
