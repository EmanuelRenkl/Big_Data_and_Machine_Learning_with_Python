{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>...</th>\n",
       "      <th>TAX PTRATIO</th>\n",
       "      <th>TAX B</th>\n",
       "      <th>TAX LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO B</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>B^2</th>\n",
       "      <th>B LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4528.8</td>\n",
       "      <td>117482.40</td>\n",
       "      <td>1474.08</td>\n",
       "      <td>234.09</td>\n",
       "      <td>6072.570</td>\n",
       "      <td>76.194</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>1976.5620</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4307.6</td>\n",
       "      <td>96049.80</td>\n",
       "      <td>2211.88</td>\n",
       "      <td>316.84</td>\n",
       "      <td>7064.820</td>\n",
       "      <td>162.692</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>3627.6660</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4307.6</td>\n",
       "      <td>95064.86</td>\n",
       "      <td>975.26</td>\n",
       "      <td>316.84</td>\n",
       "      <td>6992.374</td>\n",
       "      <td>71.734</td>\n",
       "      <td>154315.4089</td>\n",
       "      <td>1583.1049</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4151.4</td>\n",
       "      <td>87607.86</td>\n",
       "      <td>652.68</td>\n",
       "      <td>349.69</td>\n",
       "      <td>7379.581</td>\n",
       "      <td>54.978</td>\n",
       "      <td>155732.8369</td>\n",
       "      <td>1160.2122</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4151.4</td>\n",
       "      <td>88111.80</td>\n",
       "      <td>1183.26</td>\n",
       "      <td>349.69</td>\n",
       "      <td>7422.030</td>\n",
       "      <td>99.671</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>2115.4770</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  \\\n",
       "0           0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0   \n",
       "1           1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0   \n",
       "2           2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0   \n",
       "3           3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0   \n",
       "4           4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0   \n",
       "\n",
       "   ...  TAX PTRATIO      TAX B  TAX LSTAT  PTRATIO^2  PTRATIO B  \\\n",
       "0  ...       4528.8  117482.40    1474.08     234.09   6072.570   \n",
       "1  ...       4307.6   96049.80    2211.88     316.84   7064.820   \n",
       "2  ...       4307.6   95064.86     975.26     316.84   6992.374   \n",
       "3  ...       4151.4   87607.86     652.68     349.69   7379.581   \n",
       "4  ...       4151.4   88111.80    1183.26     349.69   7422.030   \n",
       "\n",
       "   PTRATIO LSTAT          B^2    B LSTAT  LSTAT^2     y  \n",
       "0         76.194  157529.6100  1976.5620  24.8004  24.0  \n",
       "1        162.692  157529.6100  3627.6660  83.5396  21.6  \n",
       "2         71.734  154315.4089  1583.1049  16.2409  34.7  \n",
       "3         54.978  155732.8369  1160.2122   8.6436  33.4  \n",
       "4         99.671  157529.6100  2115.4770  28.4089  36.2  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from exercise ”Feature Engineering” ./out/polynomials.csv \n",
    "# into a DataFrame\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "FNAME = \"02_Output/polynomials.csv\"\n",
    "df = pd.read_csv(FNAME, sep = ',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379,)\n",
      "(127,)\n",
      "(379,)\n",
      "(127,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       24.8004\n",
       "1       83.5396\n",
       "2       16.2409\n",
       "3        8.6436\n",
       "4       28.4089\n",
       "5       27.1441\n",
       "6      154.5049\n",
       "7      366.7225\n",
       "8      895.8049\n",
       "9      292.4100\n",
       "10     418.2025\n",
       "11     176.0929\n",
       "12     246.8041\n",
       "13      68.2276\n",
       "14     105.2676\n",
       "15      71.7409\n",
       "16      43.2964\n",
       "17     215.2089\n",
       "18     136.6561\n",
       "19     127.2384\n",
       "20     441.8404\n",
       "21     191.2689\n",
       "22     350.4384\n",
       "23     395.2144\n",
       "24     265.6900\n",
       "25     272.5801\n",
       "26     219.3361\n",
       "27     298.5984\n",
       "28     163.8400\n",
       "29     143.5204\n",
       "         ...   \n",
       "476    348.9424\n",
       "477    620.5081\n",
       "478    325.0809\n",
       "479    171.8721\n",
       "480    115.3476\n",
       "481     59.9076\n",
       "482     49.1401\n",
       "483    108.5764\n",
       "484    177.9556\n",
       "485    111.9364\n",
       "486    224.4004\n",
       "487    131.1025\n",
       "488    326.1636\n",
       "489    574.5609\n",
       "490    880.9024\n",
       "491    326.5249\n",
       "492    178.2225\n",
       "493    144.2401\n",
       "494    184.6881\n",
       "495    309.7600\n",
       "496    446.8996\n",
       "497    198.8100\n",
       "498    166.9264\n",
       "499    228.0100\n",
       "500    205.3489\n",
       "501     93.5089\n",
       "502     82.4464\n",
       "503     31.8096\n",
       "504     41.9904\n",
       "505     62.0944\n",
       "Name: LSTAT^2, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use column ”y” as target variable and all other columns as predicting\n",
    "# variables and split them as usual.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:,\"CRIM\",\"LSTAT^2\"]\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn a Ridge and a Lasso  model using the provided data with default\n",
    "# parameters. Why do you get a ConvergenceWarning? What are the accuracy \n",
    "# scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 340.7716   85.0084   36.6025  293.0944  665.1241  326.5249  208.2249\n  517.1076   23.1361  118.3744  719.3124   43.0336  843.9025  561.2161\n  184.6881   25.4016   27.8784   45.9684  219.3361   19.8025   28.4089\n  463.1104  949.2561   20.6116   27.1441 1184.0481   59.7529  287.6416\n   24.7009  321.4849  350.4384  171.3481  441.8404  699.6025  105.2676\n   21.0681   27.5625   64.8025  163.5841   59.29     52.1284   60.6841\n  267.3225   19.1844  620.5081  214.6225   30.25    177.9556  474.3684\n  228.01    446.8996  135.9556   88.9249  263.4129  210.8304   96.04\n  135.4896  348.1956   25.8064   90.25     35.8801   19.8025  263.0884\n  575.0404  126.5625   32.49    132.25      9.9856   38.5641   90.25\n  199.6569   35.7604    9.0601   66.5856  136.6561   52.7076   43.8244\n  772.84     41.3449  198.81     34.81    111.9364  147.3796   42.6409\n   91.0116  325.8025  104.8576  137.3584  579.8464  583.7056   58.8289\n  230.1289   16.2409  403.2064  460.5316  215.2089  277.2225   85.5625\n  176.0929  510.76    109.2025   40.4496  180.6336  361.3801   62.41\n  102.2121   12.4609  144.9616  123.21    381.0304  206.4969   65.61\n  262.7641   27.9841   40.4496  105.8841  285.61     26.01     30.1401\n   89.3025  743.1076   61.6225  413.7156 1181.2969  451.1376  294.4656\n    6.1009  225.9009  336.7225   49.1401   91.2025  208.5136   20.7936\n   43.4281   90.4401  321.1264   56.8516   93.7024  565.9641  143.5204\n   50.6944  110.8809  286.9636   93.8961  298.5984  454.5424   39.3129\n  260.4996   94.8676  556.96    454.5424  256.9609  152.0289   64.8025\n   35.7604   31.0249   89.6809  523.4944   29.0521  873.2025    8.2944\n   64.8025   47.61     65.61    265.69    182.5201   57.76    336.3556\n  103.2256   13.69    198.81    898.2009    3.9204   12.4609  201.3561\n   82.81    335.9889  107.3296   68.2276   50.9796 1367.5204  205.3489\n   15.3664    2.9929   56.4001   31.8096  171.8721  169.      460.1025\n  146.8944   43.2964   51.5524  241.8025  544.7556  340.7716   22.3729\n   91.9681  103.8361  254.0836   93.5089  528.0804   90.6304   61.3089\n  292.7521  127.2384   99.4009   54.6121  186.3225    9.7969  230.1289\n    8.6436   20.25    219.3361   14.1376  167.1849  105.4729  195.4404\n  296.1841  108.5764    8.8804  108.16    275.2281   23.2324  280.2276\n   27.9841   56.7009   60.6841  176.0929  180.6336  165.3796  218.7441\n  130.1881  224.4004   47.0596   23.4256  169.      180.9025  533.1481\n  412.4961  412.9024  246.49    645.6681   98.6049   45.2929  444.3664\n  158.76     44.6224  395.2144   55.3536  270.2736   24.8004   55.2049\n   10.6276  144.7209   12.7449   34.6921   48.0249  144.2401   47.8864\n   13.9129    9.6721  112.1481  165.6369   44.2225  328.6969  128.1424\n   77.2641   79.7449  949.2561   30.1401 1208.9529  396.8064  326.1636\n   23.5225   40.4496  802.0224  698.0164   45.5625   57.1536  309.76\n  150.3076  350.0641   41.9904   34.9281   37.4544   14.5161   92.5444\n  203.6329  326.1636  488.8521  294.1225  269.6164  938.1969   67.24\n   45.1584   55.3536  185.2321  131.7904   12.6736   15.6025  594.8721\n   47.1969   26.2144  540.0976  298.2529   33.7561  271.2609  937.5844\n  265.3641   43.2964  304.1536  102.6169  434.7225   71.0649  225.6004\n  355.3225  236.8521   11.0889  163.84     32.2624    8.7616   11.0224\n  176.3584  156.25      9.6721  170.0416  767.8441  295.4961  172.9225\n  348.9424  372.8761   57.76    542.4241  935.7481  195.7201  872.0209\n   67.7329  880.9024   39.5641   38.3161   72.4201  328.6969  387.6961\n   64.1601   74.1321   26.9361  174.7684  248.3776  749.6644  109.2025\n   30.4704   32.2624  272.5801   96.2361  111.5136  574.5609   92.9296\n  178.2225   18.6624   25.3009   86.1184  375.1969   30.25    206.2096\n   45.1584   71.2336   22.09    125.8884   17.3056  575.0404  292.41\n  160.5289    8.8209   12.8881  137.8276    8.2369  106.09    353.44\n  215.7961].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a0b7162cef16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         X, y = check_X_y(X, y, ['csr', 'csc', 'coo'], dtype=_dtype,\n\u001b[0;32m--> 483\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 340.7716   85.0084   36.6025  293.0944  665.1241  326.5249  208.2249\n  517.1076   23.1361  118.3744  719.3124   43.0336  843.9025  561.2161\n  184.6881   25.4016   27.8784   45.9684  219.3361   19.8025   28.4089\n  463.1104  949.2561   20.6116   27.1441 1184.0481   59.7529  287.6416\n   24.7009  321.4849  350.4384  171.3481  441.8404  699.6025  105.2676\n   21.0681   27.5625   64.8025  163.5841   59.29     52.1284   60.6841\n  267.3225   19.1844  620.5081  214.6225   30.25    177.9556  474.3684\n  228.01    446.8996  135.9556   88.9249  263.4129  210.8304   96.04\n  135.4896  348.1956   25.8064   90.25     35.8801   19.8025  263.0884\n  575.0404  126.5625   32.49    132.25      9.9856   38.5641   90.25\n  199.6569   35.7604    9.0601   66.5856  136.6561   52.7076   43.8244\n  772.84     41.3449  198.81     34.81    111.9364  147.3796   42.6409\n   91.0116  325.8025  104.8576  137.3584  579.8464  583.7056   58.8289\n  230.1289   16.2409  403.2064  460.5316  215.2089  277.2225   85.5625\n  176.0929  510.76    109.2025   40.4496  180.6336  361.3801   62.41\n  102.2121   12.4609  144.9616  123.21    381.0304  206.4969   65.61\n  262.7641   27.9841   40.4496  105.8841  285.61     26.01     30.1401\n   89.3025  743.1076   61.6225  413.7156 1181.2969  451.1376  294.4656\n    6.1009  225.9009  336.7225   49.1401   91.2025  208.5136   20.7936\n   43.4281   90.4401  321.1264   56.8516   93.7024  565.9641  143.5204\n   50.6944  110.8809  286.9636   93.8961  298.5984  454.5424   39.3129\n  260.4996   94.8676  556.96    454.5424  256.9609  152.0289   64.8025\n   35.7604   31.0249   89.6809  523.4944   29.0521  873.2025    8.2944\n   64.8025   47.61     65.61    265.69    182.5201   57.76    336.3556\n  103.2256   13.69    198.81    898.2009    3.9204   12.4609  201.3561\n   82.81    335.9889  107.3296   68.2276   50.9796 1367.5204  205.3489\n   15.3664    2.9929   56.4001   31.8096  171.8721  169.      460.1025\n  146.8944   43.2964   51.5524  241.8025  544.7556  340.7716   22.3729\n   91.9681  103.8361  254.0836   93.5089  528.0804   90.6304   61.3089\n  292.7521  127.2384   99.4009   54.6121  186.3225    9.7969  230.1289\n    8.6436   20.25    219.3361   14.1376  167.1849  105.4729  195.4404\n  296.1841  108.5764    8.8804  108.16    275.2281   23.2324  280.2276\n   27.9841   56.7009   60.6841  176.0929  180.6336  165.3796  218.7441\n  130.1881  224.4004   47.0596   23.4256  169.      180.9025  533.1481\n  412.4961  412.9024  246.49    645.6681   98.6049   45.2929  444.3664\n  158.76     44.6224  395.2144   55.3536  270.2736   24.8004   55.2049\n   10.6276  144.7209   12.7449   34.6921   48.0249  144.2401   47.8864\n   13.9129    9.6721  112.1481  165.6369   44.2225  328.6969  128.1424\n   77.2641   79.7449  949.2561   30.1401 1208.9529  396.8064  326.1636\n   23.5225   40.4496  802.0224  698.0164   45.5625   57.1536  309.76\n  150.3076  350.0641   41.9904   34.9281   37.4544   14.5161   92.5444\n  203.6329  326.1636  488.8521  294.1225  269.6164  938.1969   67.24\n   45.1584   55.3536  185.2321  131.7904   12.6736   15.6025  594.8721\n   47.1969   26.2144  540.0976  298.2529   33.7561  271.2609  937.5844\n  265.3641   43.2964  304.1536  102.6169  434.7225   71.0649  225.6004\n  355.3225  236.8521   11.0889  163.84     32.2624    8.7616   11.0224\n  176.3584  156.25      9.6721  170.0416  767.8441  295.4961  172.9225\n  348.9424  372.8761   57.76    542.4241  935.7481  195.7201  872.0209\n   67.7329  880.9024   39.5641   38.3161   72.4201  328.6969  387.6961\n   64.1601   74.1321   26.9361  174.7684  248.3776  749.6644  109.2025\n   30.4704   32.2624  272.5801   96.2361  111.5136  574.5609   92.9296\n  178.2225   18.6624   25.3009   86.1184  375.1969   30.25    206.2096\n   45.1584   71.2336   22.09    125.8884   17.3056  575.0404  292.41\n  160.5289    8.8209   12.8881  137.8276    8.2369  106.09    353.44\n  215.7961].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "preds = ridge.predict(X_test)\n",
    "\n",
    "print(ridge.score(X_test, y_test))\n",
    "print(ridge.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "preds = lasso.predict(X_test)\n",
    "\n",
    "print(lasso.score(X_test, y_test))\n",
    "print(lasso.score(X_train, y_train))\n",
    "\n",
    "lasso.coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why do you get a ConvergenceWarning?\n",
    "\n",
    "# You migth want to increase the amount of iterations \n",
    "# A small alpha yields lower precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing the learned coefficients of both models\n",
    "# and the feature names as index. In how many rows are the Lasso \n",
    "# coefficients equal to 0 while the Ridge coefficients are not?\n",
    "\n",
    "df2 = pd.DataFrame(df, columns = ridge.coef(), lasso.coef())\n",
    "\n",
    "df.set_index['feature names']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib.pyplot, create a horizontal bar plot of dimension 10x30 \n",
    "# showing the coefficient sizes\n",
    "\n",
    "df2['...'].value_counts().plot(kind='barh')\n",
    "\n",
    "# Save the figure as ./out/polynomials.pdf.\n",
    "\n",
    "plt.savefig('02_Output/polynomials.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
